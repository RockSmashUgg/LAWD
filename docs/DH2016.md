#Integrating Digital Epigraphies
Hugh Cayless, DC3

As one does, I had great visions for how far along we'd be on this project when I proposed my DH paper, and, as usually happens, the demands of other projects have meant much less time to work on it than I'd hoped. But while I had hoped the project would be further along than it is, we expect this to be one of those projects that take many years, and probably will never finish. So I'm not all that far behind.

Integrating Digital Epigraphies, or IDEs, is the project I'm going to talk about today. What we have to deal with in Greek Epigraphy is a large set of texts, inscribed on stone, a long time ago, and therefore subject to a great variety of difficulties: they can be hard to read; they may be broken into fragments; they are both physical, archeological, objects and texts; they may be published and republished, interpreted and reinterpreted. The basis of Epigraphy is still publications in print and the citation of those publications.

The citations take a bit of unpacking **slide**. Here's IG I³ 40, for example, which makes perfect sense to an Epigraphist, but is a little tricky for a machine to parse, particularly since it might show up in a few different forms **slide**. And of course, this refers to a publication, not directly to the inscription itself. IG I² 39 also refers to the same text, an Athenian decree concerning Chalkis from the 5th century BCE. Several articles in the Supplementum Epigraphicum Graecum refer to IG I³ 40, and those are really talking about both the publication and the inscription. It's a hairball of information tied together by citations. The point of IDEs is to figure out what we can do with this digitally, using Linked Data to make it tractable.

The first problem in designing a Linked Data system is always to figure out what the things are you're going to give names to. Since RDF provides the basic data model, you're dealing with sets of statements composed of Subjects, Predicates, And Objects. When I talk about giving names to things in this context, I mean assigning URIs to the things you want to talk about in your RDF model, and in that model, the things you want to name may be Objects (things you're saying), Subjects (the things you're saying them about), and Predicates (characterizing what you're saying about the Subjects). **slide** Here's how IDEs manages a bit of its data: this is what we know about what the Packard Humanities Institute's Epigraphy database says about IG I³ 40. **slide** Here's the same thing with some explanatory labels applied.

Subjects and Objects tend to be fairly individualistic, and Predicates to be drawn from standard ontologies. In other words, you make up names for the things in your dataset, but you tend to have a relatively small and standardized set of relationships between them that you don't make up yourself. **slide** One side-effect of this is that there aren't very good ways to talk about specific relations between entities in your system. There are ways to do it, but they're all a bit awkward. This poses a real problem for our data though, and it's the same one that SNAP will have as soon as we add services to support reconciling data from different sources. **slide** You have a database of "facts", but how do you know where those facts came from?

When we ingest data about the publication of an inscription, we generate a new name for the inscription as well as one for the publication, unless we have some way of knowing we already have a name for it so we can link it up. So we'll end up with more names than there are actual inscriptions, and we'll need to merge them, either automatically in some way, or with human intervention. **slide** There are various ways we might do that, and this is one. **slide** But then what? How should we record this intervention in our data? Possibly we don't really care about this simple example and we could get away without recording it, but what if it were something more complicated, like someone making a scholarly argument that two fragments were part of the same inscription? The simple answer is that we want to be able to say things about the relations between entities in our system.

In IDEs we do this by cheating **slide**. Instead of an RDF triple store, we use a property graph database. The named things in our system are nodes in a graph rather than members of triples, and we can structure things in such a way that all the RDF semantics are supported, but we can also say things about, say, the source relationship between an Edition and an Inscription.

There are pros and cons to this approach, **slide**. We don't need to go through any weird gyrations to talk about relationships between named things in our data, but we can still have our RDF cake, and ingest or export it. Neo4J has a very nice and powerful query language we can use. **slide** On the other hand, we lose support for SPARQL; we could end up with data we can't comfortably export as RDF, and that might pose interoperability problems, and we're more locked in in terms of data store choices.
